varimpelastic <- variable_imp(mod_elastic$beta,k=15,t=2,"elastic")
varimpforet <- variable_imp(mod_foret,k=15,t=1,"foret")
varimpada <- variable_imp(summary(mod_adaboost),k=15,t=3,"adaboost")
varimplogibo <- variable_imp(summary(mod_logiboost),k=15,t=3,"logiboost")
# Croisement des tables d'importance des variables
choix_var <- varimplog %>%
full_join(varimpridge) %>%
full_join(varimplasso) %>%
full_join(varimpelastic) %>%
full_join(varimpforet) %>%
full_join(varimpada) %>%
full_join(varimplogibo)
choix_var <- choix_var[,-c(which(grepl("^imp",names(choix_var))))]
choix_var
# 1 pour glm et randomforest, 2 pour glmnet, 3 pour gbm
variable_imp <- function(x,k=50,t=1,mot=""){
switch(t,
x <- varImp(x),
x <- as.data.frame(as.matrix(x)),
x[,1] <- NULL
)
tempo <- cbind(row.names(x),x)
row.names(tempo) <- NULL
colnames(tempo)[1] <- "variable"
colnames(tempo)[2] <-  "importance"
tempo[,1] <- gsub("YES$","",tempo[,1],ignore.case = TRUE)
tempo[,1] <- gsub("NO$","",tempo[,1],ignore.case = TRUE)
tempo <- arrange(tempo, desc(importance))[1:k,]
colnames(tempo)[2] <-  paste("imp",mot,sep = "_")
tempo$rank <- seq(1:k)
colnames(tempo)[3] <- paste("rang",mot,sep = "_")
return(tempo)
}
varimplog <- variable_imp(x=mod_log,k=15,t=1,mot="log")
varimpridge <- variable_imp(x=mod_ridge$beta,k=15,t=2,"ridge")
varimplasso <- variable_imp(x=mod_lasso$beta,k=15,t=2, "lasso")
varimpelastic <- variable_imp(mod_elastic$beta,k=15,t=2,"elastic")
varimpforet <- variable_imp(mod_foret,k=15,t=1,"foret")
varimpada <- variable_imp(summary(mod_adaboost),k=15,t=3,"adaboost")
varimplogibo <- variable_imp(summary(mod_logiboost),k=15,t=3,"logiboost")
# Croisement des tables d'importance des variables
choix_var <- varimplog %>%
full_join(varimpridge) %>%
full_join(varimplasso) %>%
full_join(varimpelastic) %>%
full_join(varimpforet) %>%
full_join(varimpada) %>%
full_join(varimplogibo)
choix_var <- choix_var[,-c(which(grepl("^imp",names(choix_var))))]
choix_var
varimplog <- variable_imp(x=mod_log,t=1,mot="log")
varimpridge <- variable_imp(x=mod_ridge$beta,t=2,"ridge")
varimpridge <- variable_imp(x=mod_ridge$beta,t=2,"ridge")
varimpridge <- variable_imp(x=mod_ridge$beta,t=2,"ridge")
varimpridge <- variable_imp(x=mod_ridge$beta,k=15,t=2,"ridge")
varimpridge <- variable_imp(x=mod_ridge$beta,t=2,"ridge")
# 1 pour glm et randomforest, 2 pour glmnet, 3 pour gbm
variable_imp <- function(x,k=10,t=1,mot=""){
switch(t,
x <- varImp(x),
x <- as.data.frame(as.matrix(x)),
x[,1] <- NULL
)
tempo <- cbind(row.names(x),x)
row.names(tempo) <- NULL
colnames(tempo)[1] <- "variable"
colnames(tempo)[2] <-  "importance"
tempo[,1] <- gsub("YES$","",tempo[,1],ignore.case = TRUE)
tempo[,1] <- gsub("NO$","",tempo[,1],ignore.case = TRUE)
tempo <- arrange(tempo, desc(importance))[1:k,]
colnames(tempo)[2] <-  paste("imp",mot,sep = "_")
tempo$rank <- seq(1:k)
colnames(tempo)[3] <- paste("rang",mot,sep = "_")
return(tempo)
}
varimpridge <- variable_imp(x=mod_ridge$beta,t=2,"ridge")
# 1 pour glm et randomforest, 2 pour glmnet, 3 pour gbm
variable_imp <- function(x,k=10,t=1,mot=""){
switch(t,
x <- varImp(x),
x <- as.data.frame(as.matrix(x)),
x[,1] <- NULL
)
tempo <- cbind(row.names(x),x)
row.names(tempo) <- NULL
colnames(tempo)[1] <- "variable"
colnames(tempo)[2] <-  "importance"
tempo[,1] <- gsub("YES$","",tempo[,1],ignore.case = TRUE)
tempo[,1] <- gsub("NO$","",tempo[,1],ignore.case = TRUE)
tempo <- arrange(tempo, desc(importance))[1:k,]
colnames(tempo)[2] <-  paste("imp",mot,sep = "_")
tempo$rank <- seq(1:k)
colnames(tempo)[3] <- paste("rang",mot,sep = "_")
return(tempo)
}
varimplog <- variable_imp(x=mod_log,t=1,mot="log")
varimpridge <- variable_imp(x=mod_ridge$beta,t=2,mot="ridge")
varimplog <- variable_imp(x=mod_log,t=1,mot="log")
varimpridge <- variable_imp(x=mod_ridge$beta,t=2,mot="ridge")
varimplasso <- variable_imp(x=mod_lasso$beta,t=2, mot="lasso")
varimpelastic <- variable_imp(mod_elastic$beta,t=2,mot = "elastic")
varimpforet <- variable_imp(mod_foret,t=1,mot="foret")
varimpada <- variable_imp(summary(mod_adaboost),t=3, mot="adaboost")
varimplogibo <- variable_imp(summary(mod_logiboost),t=3,mot="logiboost")
# 1 pour glm et randomforest, 2 pour glmnet, 3 pour gbm
variable_imp <- function(x,k=50,t=1,mot=""){
switch(t,
x <- varImp(x),
x <- as.data.frame(as.matrix(x)),
x[,1] <- NULL
)
tempo <- cbind(row.names(x),x)
row.names(tempo) <- NULL
colnames(tempo)[1] <- "variable"
colnames(tempo)[2] <-  "importance"
tempo[,1] <- gsub("YES$","",tempo[,1],ignore.case = TRUE)
tempo[,1] <- gsub("NO$","",tempo[,1],ignore.case = TRUE)
tempo <- arrange(tempo, desc(importance))[1:k,]
colnames(tempo)[2] <-  paste("imp",mot,sep = "_")
tempo$rank <- seq(1:k)
colnames(tempo)[3] <- paste("rang",mot,sep = "_")
return(tempo)
}
varimplog <- variable_imp(x=mod_log,t=1,mot="log")
varimpridge <- variable_imp(x=mod_ridge$beta,t=2,mot="ridge")
varimplasso <- variable_imp(x=mod_lasso$beta,t=2, mot="lasso")
varimpelastic <- variable_imp(mod_elastic$beta,t=2,mot = "elastic")
varimpforet <- variable_imp(mod_foret,t=1,mot="foret")
varimpada <- variable_imp(summary(mod_adaboost),t=3, mot="adaboost")
varimplogibo <- variable_imp(summary(mod_logiboost),t=3,mot="logiboost")
# Croisement des tables d'importance des variables
choix_var <- varimplog %>%
full_join(varimpridge) %>%
full_join(varimplasso) %>%
full_join(varimpelastic) %>%
full_join(varimpforet) %>%
full_join(varimpada) %>%
full_join(varimplogibo)
choix_var <- choix_var[,-c(which(grepl("^imp",names(choix_var))))]
choix_var
choix_var>15
which(choix_var>15)
choix_var
choix_var <- choix_var[,c(which(grepl("^imp",names(choix_var))))]
# Croisement des tables d'importance des variables
choix_var <- varimplog %>%
full_join(varimpridge) %>%
full_join(varimplasso) %>%
full_join(varimpelastic) %>%
full_join(varimpforet) %>%
full_join(varimpada) %>%
full_join(varimplogibo)
choix_var <- choix_var[,c(which(grepl("^imp",names(choix_var))))]
<- choix_var[,c(which(grepl("^imp",names(choix_var))))]
choix_var <- choix_var[,c(which(grepl("^imp",names(choix_var))))]
choix_var
# 1 pour glm et randomforest, 2 pour glmnet, 3 pour gbm
variable_imp <- function(x,k=15,t=1,mot=""){
switch(t,
x <- varImp(x),
x <- as.data.frame(as.matrix(x)),
x[,1] <- NULL
)
tempo <- cbind(row.names(x),x)
row.names(tempo) <- NULL
colnames(tempo)[1] <- "variable"
colnames(tempo)[2] <-  "importance"
tempo[,1] <- gsub("YES$","",tempo[,1],ignore.case = TRUE)
tempo[,1] <- gsub("NO$","",tempo[,1],ignore.case = TRUE)
tempo <- arrange(tempo, desc(importance))[1:k,]
colnames(tempo)[2] <-  paste("imp",mot,sep = "_")
tempo$rank <- seq(1:k)
colnames(tempo)[3] <- paste("rang",mot,sep = "_")
return(tempo)
}
varimplog <- variable_imp(x=mod_log,t=1,mot="log")
varimpridge <- variable_imp(x=mod_ridge$beta,t=2,mot="ridge")
varimplasso <- variable_imp(x=mod_lasso$beta,t=2, mot="lasso")
varimpelastic <- variable_imp(mod_elastic$beta,t=2,mot = "elastic")
varimpforet <- variable_imp(mod_foret,t=1,mot="foret")
varimpada <- variable_imp(summary(mod_adaboost),t=3, mot="adaboost")
varimplogibo <- variable_imp(summary(mod_logiboost),t=3,mot="logiboost")
# Croisement des tables d'importance des variables
choix_var <- varimplog %>%
full_join(varimpridge) %>%
full_join(varimplasso) %>%
full_join(varimpelastic) %>%
full_join(varimpforet) %>%
full_join(varimpada) %>%
full_join(varimplogibo)
choix_var <- choix_var[,c(which(grepl("^imp",names(choix_var))))]
choix_var
scale(choix_var)
# 1 pour glm et randomforest, 2 pour glmnet, 3 pour gbm
variable_imp <- function(x,k=10,t=1,mot=""){
switch(t,
x <- varImp(x),
x <- as.data.frame(as.matrix(x)),
x[,1] <- NULL
)
tempo <- cbind(row.names(x),x)
row.names(tempo) <- NULL
colnames(tempo)[1] <- "variable"
colnames(tempo)[2] <-  "importance"
tempo[,1] <- gsub("YES$","",tempo[,1],ignore.case = TRUE)
tempo[,1] <- gsub("NO$","",tempo[,1],ignore.case = TRUE)
tempo <- arrange(tempo, desc(importance))[1:k,]
colnames(tempo)[2] <-  paste("imp",mot,sep = "_")
tempo$rank <- seq(1:k)
colnames(tempo)[3] <- paste("rang",mot,sep = "_")
return(tempo)
}
varimplog <- variable_imp(x=mod_log,t=1,mot="log")
varimpridge <- variable_imp(x=mod_ridge$beta,t=2,mot="ridge")
varimplasso <- variable_imp(x=mod_lasso$beta,t=2, mot="lasso")
varimpelastic <- variable_imp(mod_elastic$beta,t=2,mot = "elastic")
varimpforet <- variable_imp(mod_foret,t=1,mot="foret")
varimpada <- variable_imp(summary(mod_adaboost),t=3, mot="adaboost")
varimplogibo <- variable_imp(summary(mod_logiboost),t=3,mot="logiboost")
# Croisement des tables d'importance des variables
choix_var <- varimplog %>%
full_join(varimpridge) %>%
full_join(varimplasso) %>%
full_join(varimpelastic) %>%
full_join(varimpforet) %>%
full_join(varimpada) %>%
full_join(varimplogibo)
choix_var <- choix_var[,c(which(grepl("^imp",names(choix_var))))]
choix_var
scale(choix_var)
choix_var <- choix_var[,c(1,which(grepl("^imp",names(choix_var))))]
choix_var
# Croisement des tables d'importance des variables
choix_var <- varimplog %>%
full_join(varimpridge) %>%
full_join(varimplasso) %>%
full_join(varimpelastic) %>%
full_join(varimpforet) %>%
full_join(varimpada) %>%
full_join(varimplogibo)
choix_var <- choix_var[,c(1,which(grepl("^imp",names(choix_var))))]
choix_var
scale(choix_var)
choix_var <- cbind(choix_var[,1],choix_var[,c(which(grepl("^imp",names(choix_var))))])
# Croisement des tables d'importance des variables
choix_var <- varimplog %>%
full_join(varimpridge) %>%
full_join(varimplasso) %>%
full_join(varimpelastic) %>%
full_join(varimpforet) %>%
full_join(varimpada) %>%
full_join(varimplogibo)
choix_var <- cbind(choix_var[,1],choix_var[,c(which(grepl("^imp",names(choix_var))))])
choix_var
choix_var <- cbind(choix_var[,1],scale(choix_var[,c(which(grepl("^imp",names(choix_var))))]))
# Croisement des tables d'importance des variables
choix_var <- varimplog %>%
full_join(varimpridge) %>%
full_join(varimplasso) %>%
full_join(varimpelastic) %>%
full_join(varimpforet) %>%
full_join(varimpada) %>%
full_join(varimplogibo)
choix_var <- cbind(choix_var[,1],scale(choix_var[,c(which(grepl("^imp",names(choix_var))))]))
choix_var
choix_var <- cbind(choix_var[,1],round(scale(choix_var[,c(which(grepl("^imp",names(choix_var))))])),3)
choix_var <- cbind(choix_var[,1],ceiling(scale(choix_var[,c(which(grepl("^imp",names(choix_var))))])),3)
?ceiling
choix_var <- cbind(choix_var[,1],scale(choix_var[,c(which(grepl("^imp",names(choix_var))))]))
scale(choix_var[,c(which(grepl("^imp",names(choix_var))))])
choix_var[,c(which(grepl("^imp",names(choix_var))))
choix_var <- cbind(choix_var[,1],scale(choix_var[,c(which(grepl("^imp",names(choix_var))))]))
# Croisement des tables d'importance des variables
choix_var <- varimplog %>%
full_join(varimpridge) %>%
full_join(varimplasso) %>%
full_join(varimpelastic) %>%
full_join(varimpforet) %>%
full_join(varimpada) %>%
full_join(varimplogibo)
scale(choix_var[,c(which(grepl("^imp",names(choix_var))))])
choix_var <- cbind(choix_var[,1],scale(choix_var[,c(which(grepl("^imp",names(choix_var))))]))
choix_var
choix_var <- cbind(choix_var[,1],ceiling(scale(choix_var[,c(which(grepl("^imp",names(choix_var))))]),3))
ceiling(scale(choix_var[,c(which(grepl("^imp",names(choix_var))))]),3)
choix_var <- cbind(choix_var[,1],scale(choix_var[,c(which(grepl("^imp",names(choix_var))))]))
# Croisement des tables d'importance des variables
choix_var <- varimplog %>%
full_join(varimpridge) %>%
full_join(varimplasso) %>%
full_join(varimpelastic) %>%
full_join(varimpforet) %>%
full_join(varimpada) %>%
full_join(varimplogibo)
# Croisement des tables d'importance des variables
choix_var <- varimplog %>%
full_join(varimpridge) %>%
full_join(varimplasso) %>%
full_join(varimpelastic) %>%
full_join(varimpforet) %>%
full_join(varimpada) %>%
full_join(varimplogibo)
choix_var <- cbind(choix_var[,1],ceiling(scale(choix_var[,c(which(grepl("^imp",names(choix_var))))]),3))
# Croisement des tables d'importance des variables
choix_var <- varimplog %>%
full_join(varimpridge) %>%
full_join(varimplasso) %>%
full_join(varimpelastic) %>%
full_join(varimpforet) %>%
full_join(varimpada) %>%
full_join(varimplogibo)
choix_var <- cbind(choix_var[,1],ceiling(scale(choix_var[,c(which(grepl("^imp",names(choix_var))))])))
choix_var
# Croisement des tables d'importance des variables
choix_var <- varimplog %>%
full_join(varimpridge) %>%
full_join(varimplasso) %>%
full_join(varimpelastic) %>%
full_join(varimpforet) %>%
full_join(varimpada) %>%
full_join(varimplogibo)
choix_var <- cbind(choix_var[,1],round(scale(choix_var[,c(which(grepl("^imp",names(choix_var))))]),3))
choix_var
View(mod_lasso)
library(glmnet)#contrainte
library(randomForest)#Foret
library(gbm)#Boosting
library(e1071)#SVM
library(rpart)#Arbre
library(foreach)#parallel
don <- read.csv("data/nhanes_hyper_mice.csv")
don$X <- NULL
levels(don$Y) <- c(0,1)
XX <- as.matrix(model.matrix(~.,don)[,-ncol(model.matrix(~.,don))])
YY <- as.matrix(model.matrix(~.,don)[,ncol(model.matrix(~.,don))])
bloc <- 4
ind= sample(1:nrow(don) %% 4+1)
res <- data.frame(Y=don$Y, log=0, ridge=0, lasso=0, elastic=0,
foret=0, adabo=0, logibo=0, svm=0, pm=0, arbre=0)
set.seed(1234)
deb <-   Sys.time()
foreach (i = 1:bloc, .packages = c("gbm","e1071","glmnet","randomForest", "rpart")) %dopar% {
i=1
# logisque
mod <- glm(Y~.,data=don[ind!=i,],family="binomial")
res[ind==i,"log"] <- predict(mod,don[ind==i,],type="response")
XXA <- XX[ind!=i,]
YYA <- YY[ind!=i,]
XXT <- XX[ind==i,]
# ridge
tmp <- cv.glmnet(XXA,YYA,alpha=0,family="binomial")
mod <- glmnet(XXA,YYA,alpha=0,lambda=tmp$lambda.min, family="binomial")
res[ind==i,"ridge"] <- predict(mod,newx=XXT,type="response")
# lass0
tmp <- cv.glmnet(XXA,YYA, alpha=1, family="binomial")
mod <- glmnet(XXA,YYA,alpha=1, lambda =tmp$lambda.1se,family="binomial" )
colnames(don[mod$beta@i])
res[ind==i,"lasso"] <- predict(mod,newx=XXT, type="response")
# elasticnet
tmp <- cv.glmnet(XXA,YYA, alpha=0.5, family="binomial")
mod <- glmnet(XXA,YYA,alpha = 0.5, lambda = tmp$lambda.min, family="binomial")
res[ind==i,"elastic"] <- predict(mod,newx=XXT,type="response")
# foret
mod <- randomForest(Y~., data = don[ind!=i,], ntree=500)
res[ind==i, "foret"] <- predict(mod, don[ind==i,], type="prob")[,2]
# Adaboost
tmp <- gbm(as.numeric(Y)-1~.,data = don[ind!=i,], distribution = "adaboost", interaction.depth = 2,
shrinkage = 0.1,n.trees = 500)
M <- gbm.perf(tmp)[1]
mod <- gbm(as.numeric(Y)-1~.,data = don[ind!=i,], distribution = "adaboost", interaction.depth = 2,
shrinkage = 0.1,n.trees = M)
res[ind==i, "adabo"] <- predict(mod, newdata=don[ind==i,], type = "response", n.trees = M)
# Logiboost
tmp <- gbm(as.numeric(Y)-1~.,data=don[ind!=i,], distribution="bernoulli", interaction.depth = 2,
shrinkage=0.1,n.trees=500)
M <- gbm.perf(tmp)[1]
mod <- gbm(as.numeric(Y)-1~.,data=don[ind!=i,], distribution="bernoulli", interaction.depth = 2,
shrinkage=0.1,n.trees=M)
res[ind==i, "logibo"] <- predict(mod,newdata=don[ind==i,], type= "response", n.trees = M)
# SVM
mod <- svm(Y~.,data=don[ind!=i,], kernel="linear",probability=T)
# tmp <- tune(svm,Y~.,data=don[ind!=i,], kernel="linear",probability=T,ranges =
#        list(cost=c(0.1,1,10,100)))
# mod <- tmp$best.model
res[ind==i,"svm"] <- attr(predict(mod,newdata = don[ind==i,],probability = T),"probabilities")[,2]
# arbre
mod <- rpart(Y~., data = don[ind!=i,], method="class")
res[ind==i, "arbre"] <- predict(mod, don[ind==i,], type="prob")[,2]
}
fin <- Sys.time()
fin-deb
rm(list=ls())
library(mice)
library(VIM)
library(data.table)
library(glmnet)#contrainte
library(randomForest)#Foret
library(gbm)#Boosting
library(e1071)#SVM
library(rpart)#Arbre
library(foreach)#parallel
don <- read.csv("data/nhanes_hyper_mice.csv")
don$X <- NULL
levels(don$Y) <- c(0,1)
XX <- as.matrix(model.matrix(~.,don)[,-ncol(model.matrix(~.,don))])
YY <- as.matrix(model.matrix(~.,don)[,ncol(model.matrix(~.,don))])
bloc <- 4
ind= sample(1:nrow(don) %% 4+1)
res <- data.frame(Y=don$Y, log=0, ridge=0, lasso=0, elastic=0,
foret=0, adabo=0, logibo=0, svm=0, pm=0, arbre=0)
set.seed(1234)
deb <-   Sys.time()
foreach (i = 1:bloc, .packages = c("gbm","e1071","glmnet","randomForest", "rpart")) %dopar% {
# logisque
mod <- glm(Y~.,data=don[ind!=i,],family="binomial")
res[ind==i,"log"] <- predict(mod,don[ind==i,],type="response")
XXA <- XX[ind!=i,]
YYA <- YY[ind!=i,]
XXT <- XX[ind==i,]
# ridge
tmp <- cv.glmnet(XXA,YYA,alpha=0,family="binomial")
mod <- glmnet(XXA,YYA,alpha=0,lambda=tmp$lambda.min, family="binomial")
res[ind==i,"ridge"] <- predict(mod,newx=XXT,type="response")
# lass0
tmp <- cv.glmnet(XXA,YYA, alpha=1, family="binomial")
mod <- glmnet(XXA,YYA,alpha=1, lambda =tmp$lambda.1se,family="binomial" )
colnames(don[mod$beta@i])
res[ind==i,"lasso"] <- predict(mod,newx=XXT, type="response")
# elasticnet
tmp <- cv.glmnet(XXA,YYA, alpha=0.5, family="binomial")
mod <- glmnet(XXA,YYA,alpha = 0.5, lambda = tmp$lambda.min, family="binomial")
res[ind==i,"elastic"] <- predict(mod,newx=XXT,type="response")
# foret
mod <- randomForest(Y~., data = don[ind!=i,], ntree=500)
res[ind==i, "foret"] <- predict(mod, don[ind==i,], type="prob")[,2]
# Adaboost
tmp <- gbm(as.numeric(Y)-1~.,data = don[ind!=i,], distribution = "adaboost", interaction.depth = 2,
shrinkage = 0.1,n.trees = 500)
M <- gbm.perf(tmp)[1]
mod <- gbm(as.numeric(Y)-1~.,data = don[ind!=i,], distribution = "adaboost", interaction.depth = 2,
shrinkage = 0.1,n.trees = M)
res[ind==i, "adabo"] <- predict(mod, newdata=don[ind==i,], type = "response", n.trees = M)
# Logiboost
tmp <- gbm(as.numeric(Y)-1~.,data=don[ind!=i,], distribution="bernoulli", interaction.depth = 2,
shrinkage=0.1,n.trees=500)
M <- gbm.perf(tmp)[1]
mod <- gbm(as.numeric(Y)-1~.,data=don[ind!=i,], distribution="bernoulli", interaction.depth = 2,
shrinkage=0.1,n.trees=M)
res[ind==i, "logibo"] <- predict(mod,newdata=don[ind==i,], type= "response", n.trees = M)
# SVM
mod <- svm(Y~.,data=don[ind!=i,], kernel="linear",probability=T)
# tmp <- tune(svm,Y~.,data=don[ind!=i,], kernel="linear",probability=T,ranges =
#        list(cost=c(0.1,1,10,100)))
# mod <- tmp$best.model
res[ind==i,"svm"] <- attr(predict(mod,newdata = don[ind==i,],probability = T),"probabilities")[,2]
# arbre
mod <- rpart(Y~., data = don[ind!=i,], method="class")
res[ind==i, "arbre"] <- predict(mod, don[ind==i,], type="prob")[,2]
}
fin <- Sys.time()
fin-deb
library(keras)
for (i in 1:bloc){
# instanciation du model
pm.keras <- keras_model_sequential()
# architecture
pm.keras %>%
layer_dense(units = 2, input_shape=ncol(XXA), activation = "sigmoid") %>%
layer_dense(units = 1, activation = "sigmoid")
# configuration de l'apprentissage
pm.keras %>% compile(
loss="mean_squared_error",
optimizer="sgd",
metrics="mae"
)
# lancement de l'apprentissage
pm.keras %>% fit(
XXA <- XX[ind!=i,],
YYA <- YY[ind!=i,],
epochs=80,
batch_size=8
)
# proba prediction
res[ind==i,"pm"] <- pm.keras %>% predict(XX[ind==i,])
}
# matrice de confusion
monerreur(res[,2],res[,1])#log
monerreur(res[,3],res[,1])#Ridge
monerreur(res[,4],res[,1])#Lasso
monerreur(res[,5],res[,1])#Elastic
monerreur(res[,6],res[,1])#Foret
monerreur(res[,7],res[,1])#Adabo
monerreur(res[,8],res[,1])#Logibo
monerreur(res[,9],res[,1])#SVM
monerreur(res[,10],res[,1])#perceptron
monerreur(res[,11],res[,1])#arbre
############################################
monerreur <- function(X, Y, seuil=0.5){
table(cut(X, breaks = c(0,seuil,1)), Y)
}
monerreur(res[,2],res[,1])#log
monerreur(res[,3],res[,1])#Ridge
monerreur(res[,4],res[,1])#Lasso
monerreur(res[,5],res[,1])#Elastic
monerreur(res[,6],res[,1])#Foret
monerreur(res[,7],res[,1])#Adabo
monerreur(res[,8],res[,1])#Logibo
monerreur(res[,9],res[,1])#SVM
monerreur(res[,10],res[,1])#perceptron
monerreur(res[,11],res[,1])#arbre
res
write.csv2(res,"data/res_hyp.csv",row.names = FALSE)
